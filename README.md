# Smart Home Telemetry Backend

Система сбора данных от датчиков ОДС и умного дома и управления датчиками на основе пользовательских сценариев.

Приложение использует микросервисную архитектуру и состоит из 3 сервисов:
- **Collector** - сервис для сбора информации от датчиков и пользователей. предоставляет полный функционал по REST и GRPC.
- **Aggregator** - хранит в памяти слепки состояния датчиков и при изменении состояния отправляет новые слепки в обработку.
- **Analyzer** - хранит в БД информацию о всех датчиках и пользовательских сценариях. Также обрабатывает слепки состояний
датчиков, проверяет сценарии и запускает указанные в сценариях действия.

Сервисы взаимодействуют между собой через брокер сообщений Kafka. Используется пакет **kafka-clients** и 
самописные поллеры для обработки входящих сообщений. 
Сообщения 3 типов (события датчиков, сценарии, слепки состояний) кодируются в соответствующие типы Avro и отправляются
в разные топики. Сервис **Analyzer** запускает действия путем отправки gRPC-запросов клиентским хабам, 
которые управляют датчиками и умными устройствами.

### Последовательность действий:

#### 1. Клиентский Хаб регистрирует датчики в системе по gRPC
Клиентский хаб посылает информацию по gRPC о подключенных через него датчиках в сервис **Collector**.
**Collector** отправляет эти сообщения в Kafka, откуда их забирает сервис **Analyzer** и сохраняет в базе данных.

#### 2. Пользователи отправляют (через Frontend) в систему сценарии по REST
Пользователи, через web-frontend либо мобильное приложение, создают сценарии управления
своими датчиками и умными устройствами и отправляют их по REST в сервис **Collector**.
**Collector** отправляет эти сообщения в Kafka, откуда их забирает сервис **Analyzer** и сохраняет в базе данных.

#### 3. Датчики (через Хаб) отправляют в систему события по gRPC
При срабатывании каких-либо событий датчиков, эти события через клиентский хаб отправляется по gRPC в сервис **Collector**.
**Collector** отправляет эти сообщения в Kafka, откуда их забирает сервис **Aggregator** для обработки.

#### 4. Сервис **Aggregator** забирает из Kafka событие и отправляет в Kafka снапшот
Сервис **Aggregator** хранит в памяти слепки состояний каждого хаба (снапшоты) и при получении нового события проверяет, 
изменяется ли состояние хаба или нет. Если состояние изменяется, **Aggregator** отправляет новый снапшот в Kafka,
откуда его затем забирает сервис **Analyzer**.

#### 4. Сервис **Analyzer** забирает из Kafka снапшот и проверяет сценарии
При получении нового слепка состояний хаба, сервис **Analyzer** проверяет срабатывания пользовательских сценариев для
этого хаба. Если какие-либо сценарии срабатывают, то запускается выполнения действия сценария.

#### 5. Сервис **Analyzer** отправляет Хабу команду по gRPC
Для выполнения действия, сервис **Analyzer** отправляет по gRPC команду соответствующему хабу, который управляет
указанным в сценарии устройством.

# Инфраструктурные модули (папка **/infra**)

Используются:
- Spring Boot
- Spring Cloud Eureka server
- Spring Cloud Config server

### Discovery Service
Модуль **discovery-server** реализует Service Registry - центральный управляющий модуль, обеспечивающий взаимодействие
между микросервисами, load balancing, multi-instance, health-checks и т.д.

### Configuration Service
Модуль **config-server** реализует паттерн External Configuration в качестве центрального хранилища конфигураций
для всех микросервисов, кроме **discovery-server**.

# Модули основного приложения (папка **/telemetry**)

Приложение построено на микросервисной архитектуре и содержит 3 сервиса и 2 вспомогательных модуля с
классами Avro и Protobuf объектов.
Взаимодействие между сервисами осуществляется через Kafka. Взаимодействие клиента с сервисами происходит по gRPC либо 
REST (оба интерфейса предоставляют полную функциональность и взаимозаменяемы)

Используются:
- Java ٩(◕‿◕｡)۶
- Spring Boot
- Spring MVC (REST)
- Kafka Clients
- Apache Avro + Apache Avro Maven Plugin
- gRPC Spring Boot Starter (net.devh)
- Protocol Buffers + GRPC Protobuf + Protobuf Maven Plugin
- Spring Data JPA (Hibernate)
- Spring Cloud Discovery and Configuration
- PostgreSQL

### Сервис **Collector**
Микросервис, осуществляющий прием данных от клиентского хаба и пользовательского Frontend (по gRPC ли по REST) 
и отправку их в Kafka для дальнейшей обработки другими сервисами.

### Сервис **Aggregator**
Микросервис, принимающий события датчиков из Kafka, проверяющий изменение состояния хабов и отправляющий снапшоты 
состояний в Kafka для дальнейшей обработки.

### Сервис **Analyzer**
Микросервис, принимающий из Kafka 3 вида данных - регистрация/удаление датчиков, пользовательские сценарии, снапшоты состояний хабов.
Регистрации и сценарии сохраняются в базу данных, а снапшоты используются для проверки срабатывания сценариев.
При срабатывании сценариев сервис отправляет хабам команды-действия по gRPC.

### Модули **avro-schemas** и **proto-schemas**
Эти вспомогательные модули содержат спецификации типов данных и протоколов обмена информацией через Kafka и gRPC.
Используется авто-генерация Java-классов. 
